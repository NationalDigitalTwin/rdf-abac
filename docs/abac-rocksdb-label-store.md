# Labels Store (RocksDB)

The original labels store interface `LabelsStore` formerly supported a single implementation,
`LabelsStoreImpl` which was itself an in-memory graph.

A new implementation has been added `LabelsStoreRocksDB` which uses [RocksDB](https://github.com/facebook/rocksdb) to store 
labels. This makes the label store both persistent (it is stored on disk) and removes the size restrictions and memory penalties
imposed by keeping the entire label store in memory.

## Key Classes

 * `LabelsStore` interface to any labels store
 * `LabelsStoreMem` in-memory graph-based label store implementation
 * `LabelsStoreRocksDB` RocksDB-based labels store implementation
 * `StoreFmt` interface to a store formatter for RocksDB labels stores. `LabelsStoreRocksDB` works in concert with a `StoreFmt` to determine how `(key,label)` pairs are laid out on disk. A labels store must always be used with the same kind of `StoreFmt` as it was created with, otherwise the on-disk data will make no sense to it.
 * `StoreFmtByString` is a store formatter implementation which supports the storing of labels
with nodes identified by their contents. This implementation does not require a node table.
 * `StoreFmtByNodeId` a store formatter implementation that stores nodes in the label store by their
node-id. This requires the intervention of a `NodeTable` to map between nodes and ids.
 * `StoreFmtByHash` a store formatter implementation that stores nodes in the label store by hashing the contents. This can be configured to use one of a number of differing hashing functions depending on requirements for speed, size or security. 
 * `LabelsStoreRocksDB.LabelMode` is an enum which allows the choice between `OverWrite` and `Merge` modes in RocksDB-based label stores. The modes determine whether the lists of labels for a key-triple are merged or overwritten; this is intended to be a static selection of the mode of operation of a label store, and re-opening a store in a different mode from that with which it was created will have unpredictable results.

## Test Classes

 * `BulkDirectory` tests which stream sets of files of varying sizes (some very large) into labels stores
in order to test the limits of the various labels store implementations.
 * `TestLabelMatch` basic label store unit functionality has been extended to also test the RocksDB implementations.
 * `labels.TestStoreFmt` unit tests for `StoreFmt`
 * `labels.NaiveNodeMap` test implementation of a node map, used in `BulkDirectoryRocksDBTestsByNodeId`
 * `labels.TrieNodeMap` test implementation of a space efficient node map, used in `BulkDirectoryRocksDBTestsByNodeIdTrie`.
It allows the loading of the largest test data sets, at least on a big (64GB memory M1 Max) test machine.
 * `TestStoreFmt` and its subclasses allow the unit testing of storage formats, without the presence of a RocksDB instance.

## Design

`LabelsStoreRocksDB` creates or re-opens a RocksDB database at a directory location. It is updated via `add()` methods and queried
via `labelsForTriple()`.
 * The store is keyed by triples of `(subject,predicate,object)`
 * The store understands node wildcards in triples (`Node.Any` indicates the wildcard match `*`), and which combinations of subject, predicate and object may
be wildcarded. The valid combinations are encoded in the `ABACPattern` enum. Valid wildcard/non-wildcard combinations for rules are
`SPO`, `SP*`, `S**`, `*P*`, and `***`. A list of labels (strings) can be stored for each of these forms of keys,
and a lookup (`labelsForTriple()`) will match them in `SPO`, `SP*`, `S**`, `*P*`, and `***` priority-order.
 * The implementation stores `(SPO,value)` and `(SP*,value)` entries in the same RocksDB column family,
and looks them up first (simultaneously) using a `multiGet()` method. An initial implementation attempted to maintain a sorted order,
so that the column family was always ordered `[...((S,P,O),value_1),((S,P,O2),value2),...,((S,P,*),value*),...,(S,P2,O),value_x)]`
   * There is currently no useful sorted order on keys in any of the column families; the order is simply the bytewise order of the encoding 
   of the triple. At least for id-based tables, this should result in all keys prefixed `S,P` being stored together, as the
   encoding generated by `StoreFmtByNodeId` will give these a common prefix. There is _possibly_ a small RocksDB performance benefit
   in this.
   * Note that in order to support a naturally ordered iteration of keys, we would need to add a custom comparator (simple enough in itself), except that
   for performance reasons the comparator *must* be written as a native C++ comparator; RocksDB comparators can be written in Java,
   but their performance is slow enough to be unusable except for demonstration purposes. We chose to implement the `multiGet()`-based
   lookup to avoid having to do this; there seems no pressing need.
 * There are separate column families for
`S**`, `*P*`, and `***` which are queried in serial order until a match succeeds.

`LabelsStoreRocksDB` receives a `StoreFmt` instance on construction which describes how to translate between
arrays of bytes (Java `byte[]`) in storage and nodes/labels. The same RocksDB database will always need to be
opened with the same (or a "compatible") `StoreFmt`.

Different `StoreFmt` implementations describe how they lay out nodes and labels on storage buffers.
 * `StoreFmtByString` is simplistic and does not expend complexity on reducing space usage. Nodes are encoded
more-or-less by streaming their type and string content.
 * `StoreFmtByNodeId` stores nodes by storing the type of node, and a numeric identifier generated for them
by the node table. While numeric identifiers can be 64 bits long, the encoding is optimized to save some storage by
encoding identifiers which fit in 32-bit integers into 5 bytes; a preceding byte with 4 bits holding type
information and 4 bits which, in the case of a numeric id, encode whether it is a 1-byte, 2-byte, 4-byte or 8-byte
integer.
 * Using this encoding, when all the node ids for a label store fit in 32-bit integers, keys in the SPO column family 
for non-wildcarded (`SPO`) entries will be 15 bytes
long, rather than the worst case 27 bytes; this seems significant.
 * Notice also that keys for `SP*` entries (also in the SPO column family) will be 11 bytes long, as the `Node.Any`
type has no following identifier.
 * `StoreFmtByHash` stores nodes by converting them to Strings and then acquiring the deterministic hash value 
to use as the key. This is a one-way transformation and so unlike the other formats IDs cannot be transformed back 
in to their original nodes.   

## Benchmarks

### Loading the Labels Store

The `BulkDirectory` test class contains tests which are based on the `playFiles()` method, which is designed to bulk
load large numbers of labels to a labels store, in order to confirm the sizes of labels stores that can be supported,
particularly on `RocksDB`-based stores.

* the `biggerFiles()` test is used to load a 6M label store.
* the `biggestFiles()` test is used to load a 93M label store.

The `playFiles()` method also forms the first phase of the access tests described below; we have to load a large store
before we can access it.

We find that a string-based labels store  (which does not require a node table, as no `id`s are stored) to provide the
node table can load this size of labels store.
```
Labels.createLabelsStoreRocksDBByNodeId(dbDir, new TrieNodeTable(), labelMode)
```

We also find that an id-based labels store using our test implementation of a `TrieNodeTable` to provide the
node table can load this size of labels store.
```
Labels.createLabelsStoreRocksDBByNodeId(dbDir, new TrieNodeTable(), labelMode)
```

A simplistic implementation of a node table such as `NaiveNodeTable` is too space inefficient, even on a large
machine (64GB memory, java `-Xmx16G`, to load the largest (93M labels) store.

### Accessing the Labels Store

The `BulkDirectoryRocksDB` test class contains a number of tests which are based on the `bulkLoadAndRepeatedlyRead()` method.
This method first loads a large database, then samples a fraction of the keys, which it repeatedly reads to measure/stress
the read performance of the database.

For the 3 different kinds of `NodeTable` (naive, trie-based, and none because we store direct strings)
we run 3 different sizes of tests
1. Canned (starwars) data - sample 0.02 of keys, 1000 read repeats.
2. bigger data - sample 0.001 of keys, 1000 read repeats. Thus, the same number of reads at read time as of writes at load time.
3. biggest data - sample 0.0001 of keys, 1000 read repeats. Thus, 0.1 times as many reads at read time as of writes at load time.

Note also that for reading we use an `ExecutorService` with 4 threads for the core reading of the label store / RocksDB;
this lets us take advantage of RocksDB parallelism on read, and gives us better performance than single threaded,
but the speedup is less than double, nowhere near 4x, on the M1 Max Macbook Pro
on which these tests were originally run.

Writing the original label store is batched transactionally per data file, so in practice batches of 20-30 `(key,value)`-pairs
which are written to a RocksDB `WriteBatch` before the batch is atomically flushed.

```bash
$ cd rdf-abac-core
$ mvn clean
```

String based labels store
```bash
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByString#starWarsReadLoad
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByString#biggerFilesReadLoad -Dabac.labelstore.biggerfiles=/Users/alan/Downloads/bigger_data_files
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByString#biggestFilesReadLoad -Dabac.labelstore.biggestfiles=/Users/alan/Downloads/biggest_data_files
```

results:
```
setup PT0.56S, load PT3.859S, read PT3.05S
setup PT0.408S, load PT1M17.991S, read PT1M38.853S
-
```

Naive id-table based labels store
```bash
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByNodeId#starWarsReadLoad
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByNodeId#biggerFilesReadLoad -Dabac.labelstore.biggerfiles=/Users/alan/Downloads/bigger_data_files
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByNodeId#biggestFilesReadLoad -Dabac.labelstore.biggestfiles=/Users/alan/Downloads/biggest_data_files
```

results
```
setup PT0.421S, load PT1.251S, read PT1.045S
setup PT0.544S, load PT56.27S, read PT2M2.717S
```

Trie-based id-table based labels store
```bash
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByNodeIdTrie#starWarsReadLoad
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByNodeIdTrie#biggerFilesReadLoad -Dabac.labelstore.biggerfiles=/Users/alan/Downloads/bigger_data_files
$ mvn test -Dtest=BulkDirectoryRocksDBTestsByNodeIdTrie#biggestFilesReadLoad -Dabac.labelstore.biggestfiles=/Users/alan/Downloads/biggest_data_files
```

results
```
setup PT0.375S, load PT1.28S, read PT1.327S
setup PT0.501S, load PT1M9.844S, read PT3M31.998S ..seond run.. setup PT0.403S, load PT1M9.95S, read PT2M18.48S
setup PT0.481S, load PT40M33.423S, read PT5M40.07S
```
variant with 0.001 keys, 100 read repeats. Thus, still 0.1 times as many reads at read time as of writes at load time, but using
a greater number of keys.
```
setup PT0.618S, load PT27M28.658S, read PT7M39.784S
```

#### Summary

The test has been designed so that the accessed keys are distributed randomly across the database, so that cacheing by RocksDB will 
only be effective if it can cache the data required to access a complete run across the sample of keys, which would need
(for any useful number of keys) to be the entire database. Therefore, our results for the `read` phase of tests for the biggest
files can be considered as uncached accesses, and so a lower bound on access rate for large label stores.

For the trie-based NodeTable labels store, for the biggest input, we load 95M labels variously in 30-40 minutes,
and spend 5-8 minutes making 9.5M reads. So we conclude that reading is 2x slower, even though we use 4 threads.
* Write rate of 50000 labels per second.
* Read rate of 25000 labels per second.
This is definitely not too bad relative read performance on an LSM tree; we strongly suspect that all levels of the LSM tree bar the lowest
are being cached; the performance therefore is in line with our model for LSM. Whether it is adequate for the job in hand is a different question.

### Compression

RocksDB defaults to SNAPPY compression. More unambiguously, RocksDB defaults to using compression, and the compression it uses is SNAPPY. We tested the size of the resulting SST files when configuring 
different compression algorithms. We show results for `id`-based and `string`-based RocksDB labels stores.

| Compression Type       | SST files/file size (IdTrie) | SST files/MB (String) |
|------------------------|------------------------------|-----------------------|
| NONE                   | 5/269MB                      | 19/989MB              |
| LZ4                    | 3/60MB                       | 7/331MB               |
| ZSTD (bottommost)      | 3/49MB                       | 6/229MB               |
| default/snappy         | 3/68MB                       | 7/343MB               |
| LZ4, ZSTD (bottommost) | 3/49MB                       | 6/229MB               |
|

And the encoded-to-bytes sizes of the keys and values together are:

|        | key total size | value total size |
|--------|----------------|------------------|
| Id     | 68MB           | 202MB            |
| String | 1100MB         | 202MB            |
|

As per RocksDB guidance, selecting LZ4 as our compression method, rather than defaulting to snappy,
would be a win. Also as per guidance, using the CPU-intensive ZSTD at bottommost results in
significant compression benefits.

We have therefore chosen to select
* LZ4 compression mode
* ZSTD bottommost compression

for the labels store.

#### Sensitivity to the values

We noted that all label values assigned in this test are the same. To account for this
overestimating the efficiency of compression, we replaced each label with a random new one.
This did indeed reduce the efficiency of the compression:

| Compression Type       | SST files/file size (IdTrie) | SST files/MB (String) |
|------------------------|------------------------------|-----------------------|
| LZ4, ZSTD (bottommost) | 4/182MB                      | 9/410MB               |
|

### Still to Investigate


* Handling the labels store going wrong in operation
* Open telemetry
* Stack trace, log, debug
* Making label store queryable - for investigation
* Performance testing - various Store Formats (at higher level) 
* Starting a LabelStore with the wrong storage format
* Restarting a LabelStore that does not have a persistent Node Table.